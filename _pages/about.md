---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi! This is Minxing Zhang, and I'm a second-year PhD student in CISPA under the supervision of Prof. [Michael Backes](https://cispa.de/en/about/director-page) and Dr. [Xiao Zhang](https://xiao-zhang.net/). My research interests are Security & Privacy, Trustworthy Machine Learning, and Model Behavior Explanation. I obtained my B.S. degree from Shandong University (2020) under the supervision of Dr. [Zhaochun Ren](https://renzhaochun.github.io/).
My CV is available [here](./CV.pdf).

---

### Research Interests

- Trustworthy Machine Learning
- Security and Privacy
- Model Behavior Explanation

---

### What's New!

- [08/2024] I released my implementations of PGD-based adversarial training, which is available [here](https://github.com/minxingzhang/PGD).
- [08/2024] We released our paper titled [Vera Verto: Multimodal Hijacking Attack](https://arxiv.org/abs/2408.00129) that hijacks a CV victim model to implement the adversary's own NLP task with stealthiness.
- [10/2023] Our paper titled [Generated Distributions Are All You Need for Membership Inference Attacks Against Generative Models](https://ieeexplore.ieee.org/document/10484149) was accepted by [IEEE/CVF WACV2024](https://wacv2024.thecvf.com/).
- [10/2023] We released our paper titled [Generating Less Certain Adversarial Examples Improves Robust Generalization](https://arxiv.org/abs/2310.04539) that proposes to improve robust generalization by our novel definition _Adversarial Certainty_.
- [10/2022] I started my PhD study at [CISPA](https://cispa.de/en).
- [09/2021] Our paper titled [Membership Inference Attacks Against Recommender Systems](https://dl.acm.org/doi/10.1145/3460120.3484770) was accepted by [ACM CCS 2021](https://www.sigsac.org/ccs/CCS2021/).
- [05/2021] I joined [CISPA](https://cispa.de/en) as a preparatory-phase student.
- [06/2020] I obtained my bachelor's degree from [Shandong University](https://www.sdu.edu.cn/).
